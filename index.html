<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="description" content="SVIB is the benchmark designed to address the problem of systematic visual imagination." />
    <meta name="keywords" content="SVIB, systematic generalization, imagination, perception, benchmark" />
    <meta name="author" content="Yeongbin Kim, Gautam Singh, Junyeong Park, Caglar Gulcehre, Sungjin Ahn" />
    <title>SVIB</title>
    <!-- Bootstrap core CSS -->
    <!--link href="bootstrap.min.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous" />
    <!-- Custom styles for this template -->
    <!-- <link href="offcanvas.css" rel="stylesheet" />
        -->
    <!--    <link rel="icon" href="img/favicon.gif" type="image/gif">-->
    <style type="text/css">
        .container {
            zoom: 1;
            padding-bottom: 1em;
            margin-left: auto;
            margin-right: auto;
            vertical-align: middle;
            width: 100%;
            max-width: 1000px;
            font-size: 18px;
        }

        .container_img {
            zoom: 1;
            margin-left: auto;
            margin-right: auto;
            vertical-align: middle;
            width: 100%;
            max-width: 1200px;
        }

        .paper-title {
            margin-top: 2em;
            margin-bottom: 2em;
        }

        .authors-list {
            margin-bottom: 2em;
        }

        .logo-list {
            padding-bottom: 1.5em;
            display: flex;
            flex-direction: row;
            justify-content: space-evenly;
            align-items: center;
        }

        .sample {
            list-style: none;
            display: flex;
            margin-bottom: 3em;
            padding-left: 0em;
        }

        .main_dataset {
            height: 180px;
            padding-left: 1em;
            padding-right: 1em;
            padding-top: 1em;
            padding-bottom: 1em;
        }

        .full_dataset {
            display: flex;
            flex-direction: row;
            justify-content: space-around;
            margin: 2em 0 1em 0;
        }

        .h-ul {
            list-style: none;
            display: flex;
            justify-content: center;
            margin-bottom: 1em;
            padding-left: 0em;
        }

        .h-li {
            float: left;
            margin: 0 1em 0 1em;
        }

        .v-ul {
            list-style: none;
            margin-bottom: 0em;
            padding-left: 1em;
        }

        .v-li {
            font-size: 80%;
        }

        .property {
            width: 150px;
            margin: 0 auto;
        }

        #dataset {
            background-color: #E3F4F4;
            padding-top: 1em;
            padding-bottom: 1em;
            margin-top: 1em;
            margin-bottom: 1em;
        }
    </style>
    <!-- MathJax -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
              tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                processEscapes: true
              }
            });
        </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>

<body>
    <div class="jumbotron jumbotron-fluid" style='background-color: #E3F4F4; padding-bottom: 0;'>
        <div class="container" align="center" style="padding-bottom: 4rem;">
            <div class="paper-title">
                <h1>
                    SVIB: Systematic Visual Imagination Benchmark </h1>
            </div>
            <h5>
                <!-- Authors -->
                <div class="authors-list">
                    <p class="name text-center">
                        <a target="_blank">Yeongbin Kim</a><sup>1,</sup>*, <a target="_blank">Gautam Singh</a><sup>2,</sup>*, <a target="_blank">Junyeong Park</a><sup>1</sup>, <a target="_blank">Caglar Gulcehre</a><sup>3,4</sup>, <a target="_blank">Sungjin Ahn</a><sup>1</sup><br>
                    </p>
                    <p class="text-center">
                        <sup>1</sup>KAIST, <sup>2</sup>Rutgers University, <sup>3</sup>EPFL, <sup>4</sup>Google DeepMind
                    </p>
                    <p class="text-center text-secondary">
                        *Equal Contribution
                    </p>
                </div>
                <a class="btn btn-primary" href="https://arxiv.org/abs/2311.09064">Paper</a>&nbsp; <a class="btn btn-primary" href="https://github.com/systematic-visual-imagination/svib">Github</a>&nbsp; <a class="btn btn-primary" href="#dataset">Dataset</a>&nbsp;
            </h5>
        </div>
        <div class="container logo-list">
            <img border="0" src="images/KAIST_Logo.png" style="height: 40px;" />
            &nbsp; <img border="0" src="images/rutgerslogo.png" style="height: 35px;" />
            &nbsp; <img border="0" src="images/EPFL_Logo.png" style="height: 30px;" />
            &nbsp; <img border="0" src="images/Google_DeepMind_Logo.png" style="height: 40px;" />
        </div>
    </div>
    <!--------------------- Teaser --------------------->
    <div class="container" style="padding-bottom: 0;">
        <p align="center">
            <img border="0" src="images/dsprites-saas-source.png" style="width: 7%" />
            <img border="0" src="images/dsprites-saas-target.png" style="width: 7%" />
            &nbsp; <img border="0" src="images/clevr-saas-source.png" style="width: 7%" />
            <img border="0" src="images/clevr-saas-target.png" style="width: 7%" />
            &nbsp; <img border="0" src="images/clevrtex-saas-source.png" style="width: 7%" />
            <img border="0" src="images/clevrtex-saas-target.png" style="width: 7%" />
            &nbsp; <img border="0" src="images/dsprites-nsaas-source.png" style="width: 7%" />
            <img border="0" src="images/dsprites-nsaas-target.png" style="width: 7%" />
            &nbsp; <img border="0" src="images/clevr-nsaas-source.png" style="width: 7%" />
            <img border="0" src="images/clevr-nsaas-target.png" style="width: 7%" />
            &nbsp; <img border="0" src="images/clevrtex-nsaas-source.png" style="width: 7%" />
            <img border="0" src="images/clevrtex-nsaas-target.png" style="width: 7%" />
        </p>
        <p align="center">
            <img border="0" src="images/dsprites-mmix2-source.png" style="width: 7%" />
            <img border="0" src="images/dsprites-mmix2-target.png" style="width: 7%" />
            &nbsp; <img border="0" src="images/clevr-mmix2-source.png" style="width: 7%" />
            <img border="0" src="images/clevr-mmix2-target.png" style="width: 7%" />
            &nbsp; <img border="0" src="images/clevrtex-mmix2-source.png" style="width: 7%" />
            <img border="0" src="images/clevrtex-mmix2-target.png" style="width: 7%" />
            &nbsp; <img border="0" src="images/dsprites-mnmix2-source.png" style="width: 7%" />
            <img border="0" src="images/dsprites-mnmix2-target.png" style="width: 7%" />
            &nbsp; <img border="0" src="images/clevr-mnmix2-source.png" style="width: 7%" />
            <img border="0" src="images/clevr-mnmix2-target.png" style="width: 7%" />
            &nbsp; <img border="0" src="images/clevrtex-mnmix2-source.png" style="width: 7%" />
            <img border="0" src="images/clevrtex-mnmix2-target.png" style="width: 7%" />
        </p>
    </div>
    <!--------------------- Abstract --------------------->
    <br />
    <div class="container">
        <div align="center">
            <h2>Abstract</h2>
        </div>
            <hr />
            <p align="justify">
                Systematic compositionality, or the ability to adapt to novel situations by creating a mental model of the world using reusable pieces of knowledge, remains a significant challenge in machine learning. While there has been considerable progress in the language domain, efforts towards systematic visual imagination, or envisioning the dynamical implications of a visual observation, are in their infancy. We introduce the Systematic Visual Imagination Benchmark (SVIB), the first benchmark designed to address this problem head-on. SVIB offers a novel framework for a minimal world modeling problem, where models are evaluated based on their ability to generate one-step image-to-image transformations under a latent world dynamics. The framework provides benefits such as the possibility to jointly optimize for systematic perception and imagination, a range of difficulty levels, and the ability to control the fraction of possible factor combinations used during training. We hope that this benchmark will help advance visual systematic compositionality.
            </p>

    </div>
    <!--------------------- Main Idea --------------------->
    <div class="container">
        <div align="center">
            <h2>Compositional Visual World</h2>
            <hr />
            <div style="padding: 2em 0 2em 0;">
                <p align="center">
                    <img border="0" src="images/figure-two-001.png" style="width: 100%" />
                </p>
                <p align="justify">
                    Our benchmark provides episodes consisting of two frames, referred to as the <b>input image</b> and the <b>target image</b>. These observations are procedurally generated from an underlying compositional scene state composed of two objects, each constructed as a combination of several intra-object factors such as color, shape, size, etc. In this figure, we show a rule called Shape-Swap that involves swapping the shapes of the two objects in the input scene to generate the target scene. Based on the Shape-Swap rule, we show three tasks with different levels of visual complexity.
                </p>
            </div>
        </div>
    </div>
    <div class="container">
        <div align="center">
            <h2>Systematic Training and Testing Splits</h2>
            <hr />
            <div style="padding: 2em 0 2em 0;">
                <p align="center">
                    <img border="0" src="images/alpha.png" style="width: 100%" />
                </p>
                <p align="justify">
                    This is an illustration of an example <b>compositional visual world</b> where an object's appearance can be described by its color and shape. In this example world, the training set would expose all the color and shape primitives individually. However, it would not contain all the 16 possible combinations. Rather, it would only expose a subset of them. Training splits of varying difficulty can be constructed by controlling an α parameter i.e., the fraction of all possible primitive combinations that are shown in the training episodes. In testing, we present the held-out combinations.
                </p>
            </div>
        </div>
    </div>
    <!--------------------- Downloads --------------------->
    <div class="container" id='dataset'>
        <div align="center">
            <h2>Dataset</h2>
        </div>
        <hr />
<!--        <p align="justify">-->
<!--            There are a total of 12 tasks, 4 tasks per environment (<b>SVIB-dSprites</b>, <b>SVIB-CLEVR</b>, and <b>SVIB-CLEVRTex</b>). Here, we provide three datasets based on visual complexity, each consisting of three levels of difficulty: Easy, Medium, and Hard. These three levels depend on how much various kinds of primitive combinations are covered by the training set. The training and test sets are systematically separated perfectly, ensuring that the objects in the test set do not appear anywhere in the training set. Through this, it's not only possible to aim for (1) the training performance to be as close as possible to the test performance, but also (2) to achieve this even at higher levels of difficulty.-->
<!--        </p>-->
        <p align="justify">
            Our benchmark provides a total of 12 tasks.<br><br>

            <b>Subsets.</b> The 12 tasks are divided into 3 subsets containing 4 tasks each. This division is based on the perceptual complexity of the underlying visual worlds. We refer to these 3 subsets as:
            <ol>
                <li><b>SVIB-dSprites:</b> The underlying scenes are 2-dimensional and visually simple.</li>
                <li><b>SVIB-CLEVR:</b> The underlying scenes are 3-dimensional and visually simple.</li>
                <li><b>SVIB-CLEVRTex:</b> The underlying scenes are 3-dimensional and with complex textures on the objects and in the background.</li>
            </ol>
        </p>
<br>
        <p align="justify">
            <b>Rules.</b> Within each subset of the 3 aforementioned subsets, we provide 4 tasks based on 4 rules of increasing complexity:
            <ol>
                <li><b>Single Atomic (S-A).</b> The underlying rule only modifies one factor per object. The factor modification is a function of only one causal parent. In SVIB, this corresponds to the <b>Shape-Swap</b> rule i.e., the input scene can be transformed to the target scene by swapping the shapes of the two objects while keeping the other factors e.g., color, size, etc., the same as that in the input scene.</li>
                <li><b>Multiple Atomic (M-A).</b> The underlying rule modifies multiple factors per object. The factor modification is a function of only one causal parent.</li>
                <li><b>Single Non-Atomic (S-NA).</b> The underlying rule only modifies one factor per object. Each factor modification is a function of multiple causal parents.</li>
                <li><b>Multiple Non-Atomic (M-NA).</b> The underlying rule modifies multiple factors per object. Each factor modification is a function of multiple causal parents.</li>
            </ol>
        </p>
<br>
        <p align="justify">
            <b>Splits.</b> Within each of these 12 tasks, we provide 3 training splits and 1 testing split as follows:
            <ol>
                <li><b>Easy Training Split.</b> This training split corresponds to a generous α value of 0.6. It contains 64000 episodes.</li>
                <li><b>Medium Training Split.</b> This training split corresponds to an α value of 0.4. It contains 64000 episodes.</li>
                <li><b>Hard Training Split.</b> This training split corresponds to an α value of 0.2. It contains 64000 episodes.</li>
                <li><b>Testing Split.</b> The testing split is common across all training splits. It exposes combinations not shown in any of the training splits. It contains 8000 episodes.</li>
            </ol>
        </p>
<br>
        <p align="justify">
            <b>Contents of an Episode.</b> Within each split, each episode has its own directory containing the following files:
            <ol>
                <li>Input image.</li>
                <li>Target image.</li>
                <li>Ground truth scene metadata for the input image.</li>
                <li>Ground truth scene metadata for the target image.</li>
                <li>Ground truth object masks for the input image.</li>
                <li>Ground truth object masks for the target image.</li>
            </ol>
        </p>

<!--<div style="padding: 2em 0 2em 0;">-->
<!--        <ul>-->
<!--  <li><strong>Dataset Overview</strong></li>-->
<!--  <ul>-->
<!--    <li>Total of three <b>environments</b>: <em>SVIB-dSprites</em>, <em>SVIB-CLEVR</em>, <em>SVIB-CLEVRTex</em></li>-->
<!--    <li>Each environment has three splits with distinct <b>difficulty</b>: <em>Easy</em> (α=0.6), <em>Medium</em> (α=0.4), <em>Hard</em> (α=0.2)</li>-->
<!--  </ul>-->
<!--  <br>-->

<!--  <li><strong>Variety of Tasks</strong></li>-->
<!--  <ul>-->
<!--    <li>Four <b>types of tasks</b> per environment:</li>-->
<!--    <ol type="1">-->
<!--      <li><em>Single_Atomic</em></li>-->
<!--      <li><em>Multiple_Atomic</em></li>-->
<!--      <li><em>Single_Non-Atomic</em></li>-->
<!--      <li><em>Multiple_Non-Atomic</em></li>-->
<!--    </ol>-->
<!--  </ul>-->
<!--  <br>-->

<!--  <li><strong>Data Split Details</strong></li>-->
<!--  <ul>-->
<!--    <li><b>Training</b> splits:</li>-->
<!--    <ul>-->
<!--      <li>64,000 input and target images</li>-->
<!--    </ul>-->
<!--    <li><b>Test</b> splits:</li>-->
<!--    <ul>-->
<!--      <li>8,000 out-of-distribution input and target images</li>-->
<!--    </ul>-->
<!--    <li><b>Ground-truth scene descriptions</b> and <b>object masks</b> provided for both input and target images</li>-->
<!--  </ul>-->
<!--</ul>-->
<!--</div>-->
<br>
        <br>
<h2 align="center">Download Links</h2>
        <hr>
        <ul class="sample">
            To download a preview of the benchmark, use the link: <li class="h-li"><b><a href="https://github.com/systematic-visual-imagination/svib-samples">SVIB dataset preview/sample (356 MB)</a></b></li>
        </ul>
        To download all the tasks for a specific visual complexity level and generalization difficulty, use the links below.
        <br>
        <br>
        <div style="display: flex; flex-direction: row; justify-content: space-around;">
            <!--------------------- dSprites --------------------->
            <div style="flex-grow: 1;">
                <div align="center">
                    <h3>dSprites</h3>
                </div>
                <div class="main_dataset">
                    <div align="center">
                        <h5>Object Property</h5>
                    </div>
                    <ul class="property">
                        <li>4 Shapes</li>
                        <li>4 Colors</li>
                        <li>4 Sizes</li>
                    </ul>
                </div>
                <ul class="h-ul">
                    <li class="h-li" align="center"><a href="https://drive.google.com/uc?export=download&id=1CfrgSZRQ-RDsHhK0OnmR6jz0_dqdKUEy"><b>Easy</b></br>(2GB)</a></li>
                    <li class="h-li" align="center"><a href="https://drive.google.com/uc?export=download&id=1FPzj31SKctETmkiRyomtp2PY9iFcw1Kt"><b>Medium</b></br>(2GB)</a></li>
                    <li class="h-li" align="center"><a href="https://drive.google.com/uc?export=download&id=1cANAcSP3_fhsy04lv2K17907HaFQGG6P"><b>Hard</b></br>(2GB)</a></li>
                </ul>
            </div>
            <!--------------------- CLEVR --------------------->
            <div style="flex-grow: 1; border-left: 1px solid gray;">
                <div align="center">
                    <h3>CLEVR</h3>
                </div>
                <div class="main_dataset">
                    <div align="center">
                        <h5>Object Property</h5>
                    </div>
                    <ul class="property">
                        <li>4 Shapes</li>
                        <li>6 Colors</li>
                        <li>3 Sizes</li>
                        <li>2 Materials</li>
                    </ul>
                </div>
                <ul class="h-ul">
                    <li class="h-li" align="center"><a href="https://drive.google.com/uc?export=download&id=1EtjseIx0HARiS2uRpJ6mz23U2dx2DYgH"><b>Easy</b></br>(13GB)</a></li>
                    <li class="h-li" align="center"><a href="https://drive.google.com/uc?export=download&id=17iwH6xExM-AHs4vk2odzfE_9TxhdCDAG"><b>Medium</b></br>(13GB)</a></li>
                    <li class="h-li" align="center"><a href="https://drive.google.com/uc?export=download&id=1NkbROrTu38_Wydp_3z7v_1AtSkgXEF0s"><b>Hard</b></br>(13GB)</a></li>
                </ul>
            </div>
            <!--------------------- CLEVRTex --------------------->
            <div style="flex-grow: 1; border-left: 1px solid gray;">
                <div align="center">
                    <h3>CLEVRTex</h3>
                </div>
                <div class="main_dataset">
                    <div align="center">
                        <h5>Object Property</h5>
                    </div>
                    <ul class="property">
                        <li>8 Shapes</li>
                        <li>3 Sizes</li>
                        <li>8 Materials</li>
                    </ul>
                </div>
                <ul class="h-ul">
                    <li class="h-li" align="center"><a href="https://drive.google.com/uc?export=download&id=1Zgg7qpMQVDjyiQu1rWtNGqAq1pKj1tMf"><b>Easy</b></br>(20GB)</a></li>
                    <li class="h-li" align="center"><a href="https://drive.google.com/uc?export=download&id=1iTeAyTdvxl81Yls1FnsIFzOi4I5ARD5S"><b>Medium</b></br>(20GB)</a></li>
                    <li class="h-li" align="center"><a href="https://drive.google.com/uc?export=download&id=1YgJwN6Efl7kXlXRRKiX8g9BxIKBye1zx"><b>Hard</b></br>(20GB)</a></li>
                </ul>
            </div>
        </div>
        <!--------------------- Full Dataset --------------------->
        <div align="center" style="margin: 4em 0 1em 0;">
            <h4></h4>
        </div>
        <p style="margin: 0 1.2em 0 1.2em;" align="justify">
<!--            <b>Complete Dataset Collection.</b> &nbsp;-->
<!--Here, we provide all the datasets used in the paper, including the data corresponding to <b>&alpha;</b> value of 0.0. Each dataset is further divided into four data splits based on the coverage of primitive combinations. Except for the data corresponding to <b>&alpha;</b>=0.0 and the overall dataset structure, these datasets are inherently same to the main dataset we have been providing above.-->
To download all the splits of a specific task (out of the 12 tasks), use the following links. We provide the splits associated with all α values i.e., 0.0, 0.2 (Hard Split), 0.4 (Medium Split), and 0.6 (Easy Split). The following links point to the identical dataset as above but is packaged differently in a task-wise manner.
        </p>
        <div class="full_dataset">
            <ul class="v-ul">
                <li class="v-li"><a href="https://drive.google.com/uc?export=download&id=1HK0AaSJWUZK2FRgwobxkSPdTBlCAoYVu">SVIB-dSprites: Single Atomic (5.1 GB)</a></li>
                <li class="v-li"><a href="https://drive.google.com/uc?export=download&id=1nwSmsnjfOXwPaiRzvoffUyc1kObTHPlc">SVIB-dSprites: Multiple Atomic (5.1 GB)</a></li>
                <li class="v-li"><a href="https://drive.google.com/uc?export=download&id=1r9psF5FgXoxS-9vWBGujjiSNSF-tMxie">SVIB-dSprites: Single Non-Atomic (5.1 GB)</a></li>
                <li class="v-li"><a href="https://drive.google.com/uc?export=download&id=1S9_ku62hvzxWOmqmqSO4u0COOsBRYO4k">SVIB-dSprites: Multiple Non-Atomic (5.1 GB)</a></li>
            </ul>
            <ul class="v-ul">
                <li class="v-li"><a href="https://drive.google.com/uc?export=download&id=1s4BrktVl5VvUGdKf8OX26AKqinm86Rhx">SVIB-CLEVR: Single Atomic (18 GB)</a></li>
                <li class="v-li"><a href="https://drive.google.com/uc?export=download&id=1MKMNKZpq1Q2t1U-VhaF9ys_rNiwMyDCe">SVIB-CLEVR: Multiple Atomic (18 GB)</a></li>
                <li class="v-li"><a href="https://drive.google.com/uc?export=download&id=1sV312glAtCt50BsdnlxZAvRTniFIS9oV">SVIB-CLEVR: Single Non-Atomic (18 GB)</a></li>
                <li class="v-li"><a href="https://drive.google.com/uc?export=download&id=1tPKdCAnnXr3AocMEmkt1tX3yJAQdwriO">SVIB-CLEVR: Multiple Non-Atomic (18 GB)</a></li>
            </ul>
            <ul class="v-ul">
                <li class="v-li"><a href="https://drive.google.com/uc?export=download&id=11XlN4aqGakRbncrhfVZ8dzgjlgQDtC0K">SVIB-CLEVRTex: Single Atomic (23 GB)</a></li>
                <li class="v-li"><a href="https://drive.google.com/uc?export=download&id=1jbFyjvzzB_PkICAbtklCCiw7pbdznrAX">SVIB-CLEVRTex: Multiple Atomic (23 GB)</a></li>
                <li class="v-li"><a href="https://drive.google.com/uc?export=download&id=147ejTy4q2746i6wOehE2IwHOlJaacvs1">SVIB-CLEVRTex: Single Non-Atomic (23 GB)</a></li>
                <li class="v-li"><a href="https://drive.google.com/uc?export=download&id=1WsX58i-s3TI_OxQs0XixhIZomFIQvT3n">SVIB-CLEVRTex: Multiple Non-Atomic (23 GB)</a></li>
            </ul>

        </div>

        <!--------------------- Omni-Set --------------------->
        <div align="center" style="margin: 4em 0 1em 0;">
            <h4></h4>
        </div>
        <p style="margin: 0 1.2em 0 1.2em;" align="justify">
            <b> Omni-Composition Datasets</b> &nbsp; Here, we provide an omni-composition dataset for each of the 3 subsets: SVIB-dSprites, SVIB-CLEVR, and SVIB-CLEVRTex. An omni-composition dataset is a dataset containing unpaired images that capture all possible combinations of primitives under the visual vocabulary of its corresponding environment.
        </p>
        <div class="full_dataset">
            <ul class="v-ul">
                <li class="v-li"><a href="https://drive.google.com/uc?export=download&id=1bCe84Z-gOFxFZNTXDLgyilz9_d_bza66">SVIB-dSprites: Omni-Composition (219 MB)</a></li>
            </ul>
            <ul class="v-ul">
                <li class="v-li"><a href="https://drive.google.com/uc?export=download&id=1qXXoVeWDOJCkV6ID9STUuMOtrO87Itmm">SVIB-CLEVR: Omni-Composition (2.4 GB)</a></li>
            </ul>
            <ul class="v-ul">
                <li class="v-li"><a href="https://drive.google.com/uc?export=download&id=1xG8Tc2yB03iPwjrAZJrwqcTr0O2vfzdU">SVIB-CLEVRTex: Omni-Composition (3.5 GB)</a></li>
            </ul>

        </div>

    </div>
    <br /><br /><br />
</body>

</html>